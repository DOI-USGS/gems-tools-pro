{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for validating a database one rule at a time\n",
    "I use this for testing. You can programmatically write errors into the database on purpose to check that the tool finds them.\n",
    "\n",
    "Each rule section starts with copying a source database into a scratch workspace and then modifies the database as necessary to test the rule. Checking topology is a little more difficult. With the copy, go to the map and change the geometry of one or more features, save your edits, and then come back to this notebook to check the rule.\n",
    "\n",
    "Notes:\n",
    "1. `arcpy.management.Delete(gdb_c)` at the end of each section is probably not always necessary. If the `copy` command at the beginning of a section fails, and there is no call to delete the database at the end, try adding it.\n",
    "2. most rule functions return a list, the first three items of which are used to build headers and anchors in the report htmls. List items beyond that will be the errors, usually formatted in html for the report.\n",
    "3. if you edit any of the scripts imported (modules renamed as `vd`, `gdef`, `guf`, `alc`) while Pro is open, you need to reload them before you run the code cell again. After your edits, add the line `importlib.reload(vd)`, for example, to the top of the cell and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path_to_scripts_folder = # modify this line to the path of the \\Scripts folder of the GeMS Toolbox\n",
    "sys.path.append(r\"{path_to_scripts_folder}\")\n",
    "import validate_database as vd\n",
    "import GeMS_Definition as gdef\n",
    "import GeMS_utilityFunctions as guf\n",
    "import GeMS_ALaCarte as alc\n",
    "from pathlib import Path\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb = # path\\to\\geodatabase\\or\\geopackage\n",
    "scrath = # path\\to\\writable\\scratch\\space\n",
    "gdb_n = Path(gdb).name\n",
    "gdb_c = f\"{scratch}\\\\{gdb_n}\"\n",
    "if Path(gdb).suffix == \".gpkg\":\n",
    "    is_gpkg = True\n",
    "else:\n",
    "    is_gpkg = False\n",
    "arcpy.env.overwriteOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 2.1 - no core elements missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove elements and check results\n",
    "for n in (\"DataSources\", \"DescriptionOfMapUnits\", \"GeoMaterialDict\", \"GeologicMap\", \"ContactsAndFaults\", \"MapUnitPolys\"):\n",
    "    if Path(gdb_c).exists:\n",
    "        arcpy.management.Delete(gdb_c)\n",
    "    arcpy.management.Copy(gdb, gdb_c)\n",
    "    db_dict = vd.guf.gdb_object_dict(gdb_c)\n",
    "    if n in db_dict:\n",
    "        arcpy.management.Delete(db_dict[n]['catalogPath'])\n",
    "        del db_dict[n]\n",
    "    summary = vd.rule2_1(db_dict, is_gpkg)\n",
    "    for s in summary:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# change the name of a required element\n",
    "# if the name change only includes a suffix or prefix, the tool should still identify \n",
    "# the table as a GeMS object \n",
    "importlib.reload(vd)\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "\n",
    "caf = d[\"ContactsAndFaults\"][\"catalogPath\"]\n",
    "new_caf = f\"{caf}_2\"\n",
    "arcpy.management.Rename(caf, new_caf)\n",
    "d = vd.guf.gdb_object_dict(gdb_c)\n",
    "summary = vd.rule2_1(d, is_gpkg)\n",
    "for s in summary:\n",
    "    print(s)\n",
    "\n",
    "arcpy.management.Delete(gdb_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 2.2 - no missing or misdefined fields from core elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a copy\n",
    "importlib.reload(vd)\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "\n",
    "# change the names of some fields, delete others\n",
    "change = {\"MapUnit\": \"mapunit\",\n",
    "          \"Type\": \"Type2\",\n",
    "          \"HierarchyKey\": \"HKEY\"}\n",
    "delete = (\"ExistenceConfidence\", \"Label\")\n",
    "\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = vd.guf.gdb_object_dict(gdb_c)\n",
    "for k,v in d.items():\n",
    "    table = v['catalogPath']\n",
    "    if \"fields\" in v:\n",
    "        flds = [f.name for f in v[\"fields\"]]\n",
    "        # can't use AlterField on geopackages\n",
    "        # test first.\n",
    "        if not is_gpkg:\n",
    "            for a in change:\n",
    "                if a in flds:\n",
    "                    arcpy.management.AlterField(table, a, change[a])\n",
    "                    \n",
    "        for n in delete:\n",
    "            if n in flds:\n",
    "                arcpy.management.DeleteField(table, n)\n",
    "                \n",
    "d = vd.guf.gdb_object_dict(gdb_c)\n",
    "summary = vd.check_fields(d, 2, [])\n",
    "for s in summary:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "arcpy.management.Delete(gdb_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 2.4 - no map units in MapUnitPolys that are not in DMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add a MapUnit to MapUnitPolys that is not in the DMU\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = vd.guf.gdb_object_dict(gdb_c)\n",
    "mup = d[\"MapUnitPolys\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(mup, \"MapUnit\") as cursor:\n",
    "    for i,row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = \"foo\"\n",
    "        if i == 1:\n",
    "            row[0] = \"bar\"\n",
    "        cursor.updateRow(row)\n",
    "        \n",
    "d = vd.guf.gdb_object_dict(gdb_c)\n",
    "summary = vd.check_map_units(d, 2, [], {})\n",
    "for s in summary[0]:\n",
    "    print(s)\n",
    "    \n",
    "arcpy.management.Delete(gdb_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 2.5 - no duplicate map units in dmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# copy a MapUnit value in the DMU\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = vd.guf.gdb_object_dict(gdb_c)\n",
    "dmu = d[\"DescriptionOfMapUnits\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(dmu, \"MapUnit\", where_clause=\"MapUnit is not null\" ) as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            mu = row[0]\n",
    "        if i == 1:\n",
    "            row[0] = mu\n",
    "        cursor.updateRow(row)\n",
    "        \n",
    "summary = guf.get_duplicates(dmu, \"Mapunit\")\n",
    "print(summary)\n",
    "\n",
    "arcpy.management.Delete(gdb_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 2.6 - field values in required elements are defined in glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# required element can be renamed but gems_equivalent is correctly assigned\n",
    "# and the fields are still checked\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "caf = d[\"ContactsAndFaults\"]['catalogPath']\n",
    "arcpy.management.Rename(caf, f\"{caf}_2\")\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "for k,v in d.items():\n",
    "    print(k, v[\"gems_equivalent\"])\n",
    "summary = vd.glossary_check(d, 2, [])\n",
    "for s in summary:\n",
    "    print(s)\n",
    "arcpy.management.Delete(gdb_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# rename a value in a required field\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "caf = d[\"ContactsAndFaults\"]['catalogPath']\n",
    "with arcpy.da.UpdateCursor(caf, \"Type\") as cursor:\n",
    "    for i,row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = \"foobar\"\n",
    "            cursor.updateRow(row)\n",
    "summary = vd.glossary_check(d, 2, [])\n",
    "for s in summary:\n",
    "    print(s)\n",
    "arcpy.management.Delete(gdb_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 2.7 - no duplicate terms in Glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Copy one of the terms in Glossary\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "glo = d[\"Glossary\"]['catalogPath']\n",
    "with arcpy.da.UpdateCursor(glo, \"Term\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            term = row[0]\n",
    "        if i == 1:\n",
    "            row[0] = term\n",
    "        cursor.updateRow(row)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "summary = guf.get_duplicates(glo, \"Term\")\n",
    "for s in summary:\n",
    "    print(s)\n",
    "arcpy.management.Delete(gdb_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 2.8 - all SourceIDs in required elements are in DataSources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add a DataSourceID that is not in DataSources\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "caf = d[\"ContactsAndFaults\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(caf, \"DataSourceID\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = \"foobar\"\n",
    "            cursor.updateRow(row)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "\n",
    "errors, all_sources = vd.sources_check(d, 2, [])\n",
    "print(errors)\n",
    "#print(all_sources)\n",
    "arcpy.management.Delete(gdb_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 2.9 - no duplicate DataSources_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add a duplicate DataSource_ID\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "ds = d[\"DataSources\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(ds, \"DataSources_ID\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            val = row[0]\n",
    "        if i == 1:\n",
    "            row[0] = val\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "duplicates = guf.get_duplicates(ds, \"DataSources_ID\")\n",
    "print(duplicates)\n",
    "arcpy.management.Delete(gdb_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.1 - non-core elements conform to schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add an optional GeMS-defined feature class\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "if not is_gpkg:\n",
    "    fd = \"GeologicMap\"\n",
    "    sr = d[\"GeologicMap\"][\"spatialReference\"].name   \n",
    "    fc = \"OverlayPolys\"\n",
    "else:\n",
    "    fd = \"#\"\n",
    "    sr = d[\"MapUnitPolys\"][\"spatialReference\"].name\n",
    "    fc = \"OverlayPolys\"\n",
    "\n",
    "vt = arcpy.ValueTable(3)\n",
    "vt.addRow(f\"{fd} {sr} {fc}\")\n",
    "alc.process(gdb_c, vt)\n",
    "\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "results = vd.check_fields(d, 3, [])\n",
    "for r in results[0]:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# delete required fields from this optional feature class\n",
    "fc = \"OverlayPolys\"\n",
    "delete_fields = [\"Type\", \"Label\"]\n",
    "for f in delete_fields:\n",
    "    arcpy.management.DeleteField(d[fc]['catalogPath'], f)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "results = vd.check_fields(d, 3, [])\n",
    "print(results)\n",
    "\n",
    "arcpy.management.Delete(gdb_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add a required field but with the wrong length, and type. Again, we're not checking for nullable fields\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "if not is_gpkg:\n",
    "    fd = \"GeologicMap\"\n",
    "    sr = d[\"GeologicMap\"][\"spatialReference\"].name   \n",
    "    fc = \"OverlayPolys\"\n",
    "else:\n",
    "    fd = \"#\"\n",
    "    sr = d[\"MapUnitPolys\"][\"spatialReference\"].name\n",
    "    fc = \"OverlayPolys\"\n",
    "    \n",
    "vt = arcpy.ValueTable(3)\n",
    "vt.addRow(f\"{fd} {sr} {fc}\")\n",
    "alc.process(gdb_c, vt)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "arcpy.management.DeleteField(d[\"OverlayPolys\"]['catalogPath'], \"Label\")\n",
    "# set length and f_type separately\n",
    "# length only considered if type is text\n",
    "length = 25\n",
    "f_type = \"float\"  # \"text\"\n",
    "arcpy.management.AddField(d[\"OverlayPolys\"]['catalogPath'], \"Label\", f_type, field_length=length)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "results = vd.check_fields(d, 3, [])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.2 - All MapUnitPolys and ContactsAndFaults based feature classes obey Level 3 topology rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a copy\n",
    "#arcpy.management.Copy(gdb, gdb_c)\n",
    "t_path = Path(scratch) / \"Topology.gdb\"\n",
    "if t_path.exists:\n",
    "    arcpy.management.Delete(str(t_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# noodle around with the topology\n",
    "# change names of topo pairs, etc.\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "topo_pairs = vd.rule2_1(d, is_gpkg)[1]\n",
    "topo_results = vd.check_topology(d, scratch, False, topo_pairs)\n",
    "print(topo_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.3 - no missing required values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a copy\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "workdir = Path(r\"C:\\AAA\\gems\\testing\\scratch\")\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "\n",
    "# delete a couple values from a NoNulls field\n",
    "mup = d[\"MapUnitPolys\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(mup, \"MapUnit\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = None\n",
    "        if i == 1:\n",
    "            row[0] = None\n",
    "        cursor.updateRow(row)\n",
    "        \n",
    "# d = guf.gdb_object_dict(gdb_c)\n",
    "results = vd.rule3_3(d)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.4 - no missing terms in Glossary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`defined_term_fields_list = (\n",
    "    \"Type\",\n",
    "    \"ExistenceConfidence\",\n",
    "    \"IdentityConfidence\",\n",
    "    \"ParagraphStyle\",\n",
    "    \"GeoMaterialConfidence\",\n",
    "    \"ErrorMeasure\",\n",
    "    \"AgeUnits\",\n",
    "    \"LocationMethod\",\n",
    "    \"ScientificConfidence\",\n",
    ")`\n",
    "\n",
    "Values in `defined_term_fields` fields not found in Glossary are errors. Values in non-defined fields that end in `type`, `confidence`, or `method` that are not found in Glossary are warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a copy\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "\n",
    "# add a term to a required field in a non-core table that is not in the glossary\n",
    "caf = d[\"CartographicLines\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(caf, \"Type\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = \"foobar\"\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# first get all glossary terms from a level 2 check\n",
    "msgs, all_gloss_terms = vd.glossary_check(d, 2, [])\n",
    "print(msgs)\n",
    "\n",
    "# and then use that in a level 3 check\n",
    "msgs, all_gloss_terms, warnings = vd.glossary_check(d, 3, all_gloss_terms)\n",
    "\n",
    "print(msgs)\n",
    "print(warnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.5 - no unnecessary terms in Glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a copy\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "\n",
    "# add a value to the Glossary that is not used anywhere\n",
    "gloss = d[\"Glossary\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(gloss, \"Term\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = \"foobar\"\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# need to run glossary_check at levels 2 and 3 to get all_gloss_terms\n",
    "# first get all glossary terms from a level 2 check\n",
    "results = vd.glossary_check(d, 2, [])\n",
    "all_gloss_terms = results[1]\n",
    "\n",
    "results = vd.glossary_check(d, 3, all_gloss_terms)\n",
    "all_gloss_terms = results[1]\n",
    "\n",
    "results = vd.rule3_5_and_7(d, \"glossary\", all_gloss_terms)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.6 - no missing sources in DataSources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a copy\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "\n",
    "# add a data source to a non-core GeMS table that is not in DataSources\n",
    "sta = d[\"Stations\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(sta, \"DataSourceID\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = \"DASfoobar\"\n",
    "        # delete a DataSourceID\n",
    "        if i == 1:\n",
    "            row[0] = None\n",
    "        cursor.updateRow(row)\n",
    "        \n",
    "# first run sources_check at level 2 to collect all_sources from required core elements\n",
    "all_sources = []\n",
    "msgs, all_sources = vd.sources_check(d, 2, all_sources)\n",
    "print(msgs)\n",
    "\n",
    "# then, run at level 3 to check the rest\n",
    "msgs, all_sources = vd.sources_check(d, 3, all_sources)\n",
    "print(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.7 - no unnecessary sources in DataSources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a copy\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "workdir = Path(r\"C:\\AAA\\gems\\testing\\scratch\")\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "\n",
    "# add a value to the Glossary that is not used anywhere\n",
    "ds = d[\"DataSources\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(ds, \"DataSources_ID\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = \"DASfoobar\"\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# need to run sources_check at levels 2 and 3 to get all_sources\n",
    "# first get all sources from a level 2 check\n",
    "all_sources = []\n",
    "msgs, all_sources = vd.sources_check(d, 2, all_sources)\n",
    "\n",
    "# then level 3\n",
    "msgs, all_sources = vd.sources_check(d, 3, all_sources)\n",
    "\n",
    "# then check rule3_5_and_7\n",
    "results = vd.rule3_5_and_7(d, \"datasources\", all_sources)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.8 - No map units without entries in DescriptionOfMapUnits and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a copy\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "\n",
    "# first, run check_map_units at level 2 which collects map units from MapUnitPolys\n",
    "all_map_units = []\n",
    "fds_map_units = {}\n",
    "msgs, all_map_units, fds_map_units = vd.check_map_units(d, 2, all_map_units, fds_map_units)\n",
    "\n",
    "# add a random map unit to a non-core element\n",
    "clines = d[\"Stations\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(clines, [\"MapUnit\", \"ObservedMapunit\"]) as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = \"foo\"\n",
    "        if i == 1:\n",
    "            row[1] = \"bar\"\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# and then at level 3 to extend all_map_units with units from all tables with 'MapUnit'\n",
    "(msgs3_8, msgs3_9, all_map_units, fds_map_units, mu_warnings) = vd.check_map_units(d, 3, all_map_units, fds_map_units)\n",
    "\n",
    "print(\"Rule 3.8\")\n",
    "for m in msgs3_8: \n",
    "    print(m)\n",
    "print(\"Warnings\")\n",
    "for m in mu_warnings:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.9 - No unnecessary MapUnits in DescriptionOfMapUnits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add an extra map unit to DescriptionOfMapUnits\n",
    "dmu = d[\"DescriptionOfMapUnits\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(dmu, \"MapUnit\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = \"foobar\"\n",
    "        cursor.updateRow(row)\n",
    "        \n",
    "(msgs3_8, msgs3_9, all_map_units, fds_map_units, mu_warnings) = vd.check_map_units(d, 3, all_map_units, fds_map_units)\n",
    "\n",
    "for m in msgs3_9: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.10 - HierarchyKey values in DescriptionOfMapUnits are unique and well formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a copy\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "dmu = d[\"DescriptionOfMapUnits\"][\"catalogPath\"]\n",
    "\n",
    "# take a look at the HierarchyKeys\n",
    "hkeys = [r[0] for r in arcpy.da.SearchCursor(dmu, \"HierarchyKey\")]\n",
    "hkeys.sort()\n",
    "for hkey in hkeys: print(hkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add a weird HierarchyKey\n",
    "dmu = d[\"DescriptionOfMapUnits\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(dmu, \"HierarchyKey\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = \"1/2\"\n",
    "        cursor.updateRow(row)\n",
    "results = vd.rule3_10(d)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.11 - All values of GeoMaterial are defined in GeoMaterialDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a copy\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "file = vd.__file__\n",
    "scripts = Path(file).parent\n",
    "ref_gmd = scripts /  \"GeoMaterialDict.csv\"\n",
    "\n",
    "# add a weird geomaterial\n",
    "dmu = d[\"DescriptionOfMapUnits\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(dmu, \"GeoMaterial\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = \"choss\"\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "results = vd.rule3_11(d, str(ref_gmd))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.12 - No duplicate \\_ID values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a copy\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "\n",
    "# duplicate an _ID value\n",
    "caf = d[\"ContactsAndFaults\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(caf, \"ContactsAndFaults_ID\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            val = row[0]\n",
    "        if i == 1:\n",
    "            row[0] = val\n",
    "        cursor.updateRow(row)\n",
    "results = vd.rule3_12(d)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rule 3.13 - No zero-length or whitespace-only strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a copy\n",
    "importlib.reload(vd)\n",
    "arcpy.management.Copy(gdb, gdb_c)\n",
    "d = guf.gdb_object_dict(gdb_c)\n",
    "\n",
    "# add some bad null values\n",
    "caf = d[\"ContactsAndFaults\"][\"catalogPath\"]\n",
    "with arcpy.da.UpdateCursor(caf, \"Type\") as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i == 0:\n",
    "            row[0] = \"\"\n",
    "        if i == 1:\n",
    "            row[0] = \" \"\n",
    "        if i == 2:\n",
    "            row[0] = \"<NULL>\"\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "results = vd.rule3_13(d)\n",
    "zero = results[0]\n",
    "leading = results[1]\n",
    "for z in zero: print(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
